{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph\n",
    "import importlib\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import schedule as sch\n",
    "import topo\n",
    "import typing\n",
    "import utils\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "matplotlib.rc('font', family='Times New Roman', size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_size_cb(r: int):\n",
    "    return 10000 * math.pow(10, random.randint(0, 1))\n",
    "\n",
    "def gen_graphs(graph_count, source_selector_dict):\n",
    "    source_selector = graph.SourceSelector(source_selector_dict)\n",
    "    gen_args_list = [\n",
    "            {\n",
    "            \"total_rank\": random.randint(3, 7),\n",
    "            \"max_node_per_rank\": random.randint(1, 4),\n",
    "            \"max_predecessors\": random.randint(1, 3),\n",
    "            \"mi_cb\": lambda: 1,\n",
    "            \"memory_cb\": lambda: int(2e8),\n",
    "            \"unit_size_cb\": unit_size_cb,\n",
    "            \"unit_rate_cb\": lambda: random.randint(10, 20),\n",
    "            \"source_hosts\": source_selector,\n",
    "            \"sink_hosts\": [\"cloud1\"],\n",
    "        }\n",
    "        for _ in range(graph_count)\n",
    "    ]\n",
    "    return [\n",
    "        graph.GraphGenerator(\"g\" + str(idx), **gen_args).gen_dag_graph()\n",
    "        for idx, gen_args in enumerate(gen_args_list)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_avg(array):\n",
    "    return sum(array) / len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(sc, labels, source_selector_dict):\n",
    "    flow_bp_data = [[] for _ in labels]\n",
    "    all_cloud_bp_data = [[] for _ in labels]\n",
    "    flow_event_data = [[] for _ in labels]\n",
    "    all_cloud_event_data = [[] for _ in labels]\n",
    "    edge_random_event_data = [[] for _ in labels]\n",
    "    test_round = 100\n",
    "    pbar = tqdm(total=len(labels)*test_round)\n",
    "    for idx, graph_count in enumerate(labels):\n",
    "        for _ in range(test_round):\n",
    "            graph_list = gen_graphs(graph_count, source_selector_dict)\n",
    "            sc.topo.clear_occupied()\n",
    "            flow_scheduler = sch.FlowScheduler(sc)\n",
    "            flow_calculator = sch.LatencyCalculator(sc.topo)\n",
    "            flow_result_list = flow_scheduler.schedule_multiple(graph_list)\n",
    "            for g, result in zip(graph_list, flow_result_list):\n",
    "                assert result is not None\n",
    "                flow_calculator.add_scheduled_graph(g, result)\n",
    "            flow_latency, flow_bp = flow_calculator.compute_latency()\n",
    "            for g in graph_list:\n",
    "                flow_event_data[idx].append(flow_latency[g.uuid] / g.number_of_vertices())\n",
    "                flow_bp_data[idx].append(flow_bp[g.uuid])\n",
    "\n",
    "            sc.topo.clear_occupied()\n",
    "            all_cloud_scheduler = sch.AllCloudScheduler(sc)\n",
    "            all_cloud_calculator = sch.LatencyCalculator(sc.topo)\n",
    "            all_cloud_result_list = all_cloud_scheduler.schedule_multiple(graph_list)\n",
    "            for g, result in zip(graph_list, all_cloud_result_list):\n",
    "                assert result is not None\n",
    "                all_cloud_calculator.add_scheduled_graph(g, result)\n",
    "            all_cloud_latency, all_cloud_bp = all_cloud_calculator.compute_latency()\n",
    "            for g in graph_list:\n",
    "                all_cloud_event_data[idx].append(all_cloud_latency[g.uuid] / g.number_of_vertices())\n",
    "                all_cloud_bp_data[idx].append(all_cloud_bp[g.uuid])\n",
    "\n",
    "            pbar.update()\n",
    "    flow_event_data = [big_avg(i) for i in flow_event_data]\n",
    "    flow_bp_data = [big_avg(i) for i in flow_bp_data]\n",
    "    all_cloud_event_data = [big_avg(i) for i in all_cloud_event_data]\n",
    "    all_cloud_bp_data = [big_avg(i) for i in all_cloud_bp_data]\n",
    "    return flow_event_data, flow_bp_data, all_cloud_event_data, all_cloud_bp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud0_router -> cloud_switch: 325.66\n",
      "cloud0_router -> edge0_router: 325.66\n",
      "cloud_switch -> cloud1: 325.66\n",
      "edge0_router -> rasp_switch: 114.27\n",
      "edge0_router -> vm_switch: 211.39\n",
      "rasp_switch -> rasp1: 18.21\n",
      "rasp_switch -> rasp2: 22.79\n",
      "rasp_switch -> rasp3: 22.89\n",
      "rasp_switch -> rasp4: 15.15\n",
      "rasp_switch -> rasp5: 9.38\n",
      "rasp_switch -> rasp6: 35.65\n",
      "vm_switch -> vm1: 33.61\n",
      "vm_switch -> vm2: 33.02\n",
      "vm_switch -> vm3: 32.55\n",
      "vm_switch -> vm4: 55.69\n",
      "vm_switch -> vm5: 41.6\n",
      "vm_switch -> vm6: 43.52\n"
     ]
    }
   ],
   "source": [
    "# sc = topo.Scenario.from_dict(yaml.load(open(\"../../samples/1e3h.yaml\", \"r\").read(), Loader=yaml.Loader))\n",
    "sc = topo.Scenario.from_dict(yaml.load(open(\"../../samples/1e12h.yaml\", \"r\").read(), Loader=yaml.Loader))\n",
    "# sc = topo.Scenario.from_dict(yaml.load(open(\"../../samples/1e40h.yaml\", \"r\").read(), Loader=yaml.Loader))\n",
    "graph_count = 120\n",
    "# source_dict = {'rasp1': 8, 'rasp2': 8, 'rasp3': 8}\n",
    "source_dict = {'rasp'+str(i): 8 for i in range(1, 7)}\n",
    "source_dict.update({'vm'+str(i): 16 for i in range(1, 7)})\n",
    "# source_dict = {'e0rasp'+str(i): 8 for i in range(1, 9)}\n",
    "# source_dict.update({'e1rasp'+str(i): 8 for i in range(1, 9)})\n",
    "# source_dict.update({'e0vm'+str(i): 16 for i in range(1, 9)})\n",
    "# source_dict.update({'e1vm'+str(i): 16 for i in range(1, 9)})\n",
    "# source_dict.update({'e0desktop'+str(i): 32 for i in range(1, 5)})\n",
    "# source_dict.update({'e1desktop'+str(i): 32 for i in range(1, 5)})\n",
    "graph_list = gen_graphs(graph_count, source_dict)\n",
    "sc.topo.clear_occupied()\n",
    "flow_scheduler = sch.FlowScheduler(sc)\n",
    "flow_calculator = sch.LatencyCalculator(sc.topo)\n",
    "flow_result_list = flow_scheduler.schedule_multiple(graph_list)\n",
    "for g, result in zip(graph_list, flow_result_list):\n",
    "    assert result is not None\n",
    "    flow_calculator.add_scheduled_graph(g, result)\n",
    "for u, v, data in sc.topo.g.edges(data=True):\n",
    "    print('{} -> {}: {}'.format(u, v, data['occupied'] / 1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rerun & debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebalance round 0\n",
      "rebalance round 1\n",
      "rebalance round 2\n",
      "rebalance round 3\n",
      "rebalance round 0\n",
      "rebalance round 1\n",
      "rebalance round 2\n",
      "rebalance round 3\n",
      "rebalance round 0\n",
      "rebalance round 1\n",
      "rebalance round 2\n",
      "rebalance round 3\n",
      "edge0 run provisioning\n",
      "rebalance round 0\n",
      "rebalance round 1\n",
      "rebalance round 2\n",
      "rebalance round 3\n",
      "rebalance round 4\n",
      "rebalance round 5\n",
      "cloud0 run provisioning\n",
      "rebalance round 0\n",
      "rebalance round 1\n",
      "rebalance round 2\n",
      "rebalance round 3\n",
      "edge1 run provisioning\n",
      "rebalance round 0\n",
      "rebalance round 1\n",
      "rebalance round 2\n",
      "rebalance round 3\n",
      "rebalance round 4\n",
      "rebalance round 5\n",
      "cloud0 run provisioning\n",
      "rebalance round 0\n",
      "rebalance round 1\n",
      "rebalance round 2\n",
      "rebalance round 3\n",
      "cloud0_router -> cloud_switch: 1699.88\n",
      "cloud0_router -> edge0_router: 876.97\n",
      "cloud0_router -> edge1_router: 822.91\n",
      "cloud_switch -> cloud1: 1699.88\n",
      "edge0_router -> e0rasp_switch: 202.46\n",
      "edge0_router -> e0vm_switch: 383.42\n",
      "edge0_router -> e0desktop_switch: 323.69\n",
      "edge0_router -> edge1_router: 0.0\n",
      "e0rasp_switch -> e0rasp1: 30.86\n",
      "e0rasp_switch -> e0rasp2: 39.35\n",
      "e0rasp_switch -> e0rasp3: 28.56\n",
      "e0rasp_switch -> e0rasp4: 36.59\n",
      "e0rasp_switch -> e0rasp5: 15.79\n",
      "e0rasp_switch -> e0rasp6: 24.69\n",
      "e0rasp_switch -> e0rasp7: 16.36\n",
      "e0rasp_switch -> e0rasp8: 33.14\n",
      "e0vm_switch -> e0vm1: 37.13\n",
      "e0vm_switch -> e0vm2: 68.34\n",
      "e0vm_switch -> e0vm3: 44.1\n",
      "e0vm_switch -> e0vm4: 51.28\n",
      "e0vm_switch -> e0vm5: 48.83\n",
      "e0vm_switch -> e0vm6: 41.12\n",
      "e0vm_switch -> e0vm7: 46.23\n",
      "e0vm_switch -> e0vm8: 54.79\n",
      "e0desktop_switch -> e0desktop1: 90.31\n",
      "e0desktop_switch -> e0desktop2: 85.3\n",
      "e0desktop_switch -> e0desktop3: 80.51\n",
      "e0desktop_switch -> e0desktop4: 71.97\n",
      "edge1_router -> e1rasp_switch: 170.33\n",
      "edge1_router -> e1vm_switch: 320.82\n",
      "edge1_router -> e1desktop_switch: 378.36\n",
      "e1rasp_switch -> e1rasp1: 36.53\n",
      "e1rasp_switch -> e1rasp2: 16.35\n",
      "e1rasp_switch -> e1rasp3: 17.88\n",
      "e1rasp_switch -> e1rasp4: 20.32\n",
      "e1rasp_switch -> e1rasp5: 26.08\n",
      "e1rasp_switch -> e1rasp6: 24.05\n",
      "e1rasp_switch -> e1rasp7: 19.2\n",
      "e1rasp_switch -> e1rasp8: 23.98\n",
      "e1vm_switch -> e1vm1: 36.88\n",
      "e1vm_switch -> e1vm2: 31.18\n",
      "e1vm_switch -> e1vm3: 36.45\n",
      "e1vm_switch -> e1vm4: 60.17\n",
      "e1vm_switch -> e1vm5: 47.9\n",
      "e1vm_switch -> e1vm6: 38.81\n",
      "e1vm_switch -> e1vm7: 32.65\n",
      "e1vm_switch -> e1vm8: 46.98\n",
      "e1desktop_switch -> e1desktop1: 94.92\n",
      "e1desktop_switch -> e1desktop2: 88.01\n",
      "e1desktop_switch -> e1desktop3: 116.74\n",
      "e1desktop_switch -> e1desktop4: 96.69\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sch)\n",
    "importlib.reload(sch.flow_provisioner)\n",
    "sc = topo.Scenario.from_dict(yaml.load(open(\"../../samples/1e40h.yaml\", \"r\").read(), Loader=yaml.Loader))\n",
    "graph_list = graph.ExecutionGraph.load_all(open('./debug-graphs.yaml', 'r'))\n",
    "sc.topo.clear_occupied()\n",
    "flow_scheduler = sch.FlowScheduler(sc)\n",
    "flow_calculator = sch.LatencyCalculator(sc.topo)\n",
    "flow_result_list = flow_scheduler.schedule_multiple(graph_list)\n",
    "for g, result in zip(graph_list, flow_result_list):\n",
    "    assert result is not None\n",
    "    flow_calculator.add_scheduled_graph(g, result)\n",
    "for u, v, data in sc.topo.g.edges(data=True):\n",
    "    print('{} -> {}: {}'.format(u, v, data['occupied'] / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud0_router -> cloud_switch: 1699.88\n",
      "cloud0_router -> edge0_router: 876.97\n",
      "cloud0_router -> edge1_router: 822.91\n",
      "cloud_switch -> cloud1: 1699.88\n",
      "edge0_router -> e0rasp_switch: 237.1\n",
      "edge0_router -> e0vm_switch: 421.15\n",
      "edge0_router -> e0desktop_switch: 369.02\n",
      "edge0_router -> edge1_router: 0.0\n",
      "e0rasp_switch -> e0rasp1: 35.56\n",
      "e0rasp_switch -> e0rasp2: 38.66\n",
      "e0rasp_switch -> e0rasp3: 32.59\n",
      "e0rasp_switch -> e0rasp4: 39.29\n",
      "e0rasp_switch -> e0rasp5: 28.3\n",
      "e0rasp_switch -> e0rasp6: 25.21\n",
      "e0rasp_switch -> e0rasp7: 20.49\n",
      "e0rasp_switch -> e0rasp8: 34.4\n",
      "e0vm_switch -> e0vm1: 43.08\n",
      "e0vm_switch -> e0vm2: 77.23\n",
      "e0vm_switch -> e0vm3: 48.83\n",
      "e0vm_switch -> e0vm4: 61.55\n",
      "e0vm_switch -> e0vm5: 57.94\n",
      "e0vm_switch -> e0vm6: 50.03\n",
      "e0vm_switch -> e0vm7: 58.74\n",
      "e0vm_switch -> e0vm8: 58.55\n",
      "e0desktop_switch -> e0desktop1: 113.39\n",
      "e0desktop_switch -> e0desktop2: 95.77\n",
      "e0desktop_switch -> e0desktop3: 91.68\n",
      "e0desktop_switch -> e0desktop4: 94.38\n",
      "edge1_router -> e1rasp_switch: 183.75\n",
      "edge1_router -> e1vm_switch: 358.49\n",
      "edge1_router -> e1desktop_switch: 413.49\n",
      "e1rasp_switch -> e1rasp1: 36.53\n",
      "e1rasp_switch -> e1rasp2: 16.35\n",
      "e1rasp_switch -> e1rasp3: 21.53\n",
      "e1rasp_switch -> e1rasp4: 18.82\n",
      "e1rasp_switch -> e1rasp5: 25.29\n",
      "e1rasp_switch -> e1rasp6: 24.05\n",
      "e1rasp_switch -> e1rasp7: 19.12\n",
      "e1rasp_switch -> e1rasp8: 25.72\n",
      "e1vm_switch -> e1vm1: 48.35\n",
      "e1vm_switch -> e1vm2: 40.52\n",
      "e1vm_switch -> e1vm3: 48.51\n",
      "e1vm_switch -> e1vm4: 69.01\n",
      "e1vm_switch -> e1vm5: 54.65\n",
      "e1vm_switch -> e1vm6: 48.63\n",
      "e1vm_switch -> e1vm7: 40.19\n",
      "e1vm_switch -> e1vm8: 56.03\n",
      "e1desktop_switch -> e1desktop1: 108.72\n",
      "e1desktop_switch -> e1desktop2: 98.11\n",
      "e1desktop_switch -> e1desktop3: 126.35\n",
      "e1desktop_switch -> e1desktop4: 108.91\n"
     ]
    }
   ],
   "source": [
    "sc.topo.clear_occupied()\n",
    "edge_scheduler = sch.EdgeRandomScheduler(sc)\n",
    "edge_calculator = sch.LatencyCalculator(sc.topo)\n",
    "edge_result_list = edge_scheduler.schedule_multiple(graph_list)\n",
    "for g, result in zip(graph_list, edge_result_list):\n",
    "    assert result is not None\n",
    "    edge_calculator.add_scheduled_graph(g, result)\n",
    "for u, v, data in sc.topo.g.edges(data=True):\n",
    "    print('{} -> {}: {}'.format(u, v, data['occupied'] / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'host': 'e1vm5'}\n"
     ]
    }
   ],
   "source": [
    "print(graph_list[407].get_sources()[0].domain_constraint)\n",
    "provisioner = flow_scheduler.get_provisioner(\"edge1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_node in provisioner.tree.name_lookup_map.values():\n",
    "    for v in p_node.scheduled_vertices:\n",
    "        if v.uuid == 'g407-v21':\n",
    "            print('found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privisioner Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7802447c5fd4cd88fe06cd16e279f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:08<00:00, 14.54it/s]\n"
     ]
    }
   ],
   "source": [
    "import schedule.flow_provisioner as prov\n",
    "importlib.reload(prov)\n",
    "max_round = 1000\n",
    "source_dict = {'e0rasp'+str(i): 8 for i in range(1, 9)}\n",
    "# source_dict.update({'e1rasp'+str(i): 8 for i in range(1, 9)})\n",
    "source_dict.update({'e0vm'+str(i): 16 for i in range(1, 9)})\n",
    "# source_dict.update({'e1vm'+str(i): 16 for i in range(1, 9)})\n",
    "source_dict.update({'e0desktop'+str(i): 32 for i in range(1, 5)})\n",
    "# source_dict.update({'e1desktop'+str(i): 32 for i in range(1, 5)})\n",
    "pbar = tqdm(total=max_round)\n",
    "while max_round > 0:\n",
    "    # print('---', max_round, '---')\n",
    "    sc.topo.clear_occupied()\n",
    "    source_selector = graph.SourceSelector(source_dict)\n",
    "    gen_args = {\n",
    "            \"total_rank\": random.randint(3, 7),\n",
    "            \"max_node_per_rank\": random.randint(2, 5),\n",
    "            \"max_predecessors\": random.randint(1, 4),\n",
    "            \"mi_cb\": lambda: 1,\n",
    "            \"memory_cb\": lambda: int(2e8),\n",
    "            \"unit_size_cb\": unit_size_cb,\n",
    "            \"unit_rate_cb\": lambda: random.randint(10, 20),\n",
    "            \"source_hosts\": source_selector,\n",
    "            \"sink_hosts\": [\"cloud1\"],\n",
    "        }\n",
    "    g = graph.GraphGenerator(\"g\", **gen_args).gen_dag_graph()\n",
    "    # print(g.number_of_vertices())\n",
    "    provisioner = prov.TopologicalProvisioner(sc.get_edge_domains()[0])\n",
    "    op_set = set([v.uuid for v in g.get_vertices()]) - set([v.uuid for v in g.get_sinks()])\n",
    "    provisioner.schedule(g.sub_graph(op_set, \"g\"))\n",
    "    max_round -= 1\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./debug-graphs.yaml', 'w') as f:\n",
    "    graph.ExecutionGraph.save_all(graph_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "add1a61ff37513b0d798fa9b3ddbf8ae573dfe73fde377561c8d981e86c7d8d4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
